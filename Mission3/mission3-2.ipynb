{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위 100명의 선호도 정보 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _df_load(path, state='train'):\n",
    "    df = pd.read_csv(path)\n",
    "    df_count = df.groupby(['응답자 ID']).size()\n",
    "    df_count.name = f'{state} 설문 응답 수'\n",
    "\n",
    "    return df, df_count\n",
    "\n",
    "def _top100_filtering(df, top100_ids, state='train', save=True):\n",
    "    top100_df = df[df['응답자 ID'].isin(top100_ids)].reset_index(drop=True)\n",
    "    if save:\n",
    "        top100_df.to_csv(f'top100_{state}_preference.csv', index=False)\n",
    "    \n",
    "    return top100_df\n",
    "\n",
    "def make_top100_csv(train_csv, val_csv, save=True):\n",
    "    # csv 파일로부터 데이터 불러오기\n",
    "    df_train, train_count = _df_load(train_csv, 'train')\n",
    "    df_val, val_count = _df_load(val_csv, 'val')\n",
    "\n",
    "    # 몇 가지 전처리\n",
    "    df_sum = pd.concat([train_count, val_count],axis=1)\n",
    "    df_sum = df_sum.fillna(0).astype(int)    # 결측치 0으로 채우기\n",
    "    df_sum['합계'] = df_sum['train 설문 응답 수'] + df_sum['val 설문 응답 수']    # '합계' 열 추가\n",
    "    df_sum = df_sum.sort_values(by='합계', ascending=False)    # '합계' 열 기준으로 내림차순 정렬\n",
    "\n",
    "    # df_sum의 합계를 기준으로 상위 100개 응답자 ID 추출하여 리스트로 저장\n",
    "    top100_ids = df_sum.head(100).index.tolist()\n",
    "\n",
    "    # 상위 100개의 유효한 응답자 ID를 가진 데이터만 추출\n",
    "    top100_train_df = _top100_filtering(df_train, top100_ids, 'train', save=save)\n",
    "    top100_val_df = _top100_filtering(df_val, top100_ids, 'val', save=save)\n",
    "\n",
    "    return top100_train_df, top100_val_df\n",
    "\n",
    "\n",
    "# Mission 2-2에서 생성한 csv 파일의 경로\n",
    "t_pref = 'train_preference.csv'\n",
    "v_pref = 'val_preference.csv'\n",
    "\n",
    "#t_top100_pref, v_top100_pref = make_top100_csv(t_pref, v_pref, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex;\"><div style=\"margin-right:30px;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>파일명</th>\n",
       "      <th>스타일 선호 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06753_60_mods_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06686_70_hippie_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368</td>\n",
       "      <td>W_15453_70_hippie_M.jpg</td>\n",
       "      <td>스타일 비선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06843_60_mods_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06896_10_sportivecasual_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style=\"margin-right:30px;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>파일명</th>\n",
       "      <th>스타일 선호 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>W_04622_60_mods_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368</td>\n",
       "      <td>W_04678_50_ivy_M.jpg</td>\n",
       "      <td>스타일 선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368</td>\n",
       "      <td>W_15791_70_hippie_M.jpg</td>\n",
       "      <td>스타일 비선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368</td>\n",
       "      <td>W_16034_80_bold_M.jpg</td>\n",
       "      <td>스타일 비선호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06551_60_mods_M.jpg</td>\n",
       "      <td>스타일 비선호</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 보기 좋게 HTML편집\n",
    "from IPython.display import display_html\n",
    "def display_left(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += f'<div style=\"margin-right:30px;\">{df.to_html()}</div>'\n",
    "    display_html(f'<div style=\"display: flex;\">{html_str}</div>', raw=True)\n",
    "\n",
    "# 데이터 결과 미리 확인\n",
    "display_left(t_top100_pref.head(), v_top100_pref.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data로부터 feature vector 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 패키지 import \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# 모델 재현을 위한 랜덤시드 고정\n",
    "def set_random_seed(seed_value=42):\n",
    "    # Python의 기본 난수 시드 설정\n",
    "    random.seed(seed_value)\n",
    "    # NumPy 난수 시드 설정\n",
    "    np.random.seed(seed_value)\n",
    "    # PyTorch 난수 시드 설정 (CPU)\n",
    "    torch.manual_seed(seed_value)\n",
    "    # PyTorch 난수 시드 설정 (GPU)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    # CuDNN 설정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 1-2에서 사용한 ResNet18 모델 구조 가져오기\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=31):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 가중치로 모델 불러오기\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = ResNet18(num_classes=31)    # 모델 생성\n",
    "model.load_state_dict(torch.load('./best_model.pth', weights_only=True))    # 가중치 로드\n",
    "model = model.to(device)\n",
    "model.eval()        # 학습을 하는 것이 아니므로 eval 모드로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 추출을 위한 Class 선언\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])    # 마지막 fc layer 제외\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "feature_extractor = FeatureExtractor(model)\n",
    "feature_extractor = feature_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 함수(모델 학습 시 적용한 전처리와 동일하게 적용)\n",
    "def _preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "# feature vector 추출 함수\n",
    "def _extract_features(image_path):\n",
    "    image = _preprocess_image(image_path).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# 여러 이미지로부터 feature vector 추출\n",
    "def extract_features_from_images(dir_path, image_list):\n",
    "    features = {}\n",
    "    for img in image_list:\n",
    "        path = os.path.join(dir_path, img)\n",
    "        feature = _extract_features(path)\n",
    "        features[img] = np.array(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 train image에 대한 feature vector 추출(시간이 꽤 걸릴 수 있음)\n",
    "t_img_dir = '../dataset/training_image'\n",
    "t_img_list = os.listdir(t_img_dir)\n",
    "\n",
    "extracted_features = extract_features_from_images(t_img_dir, t_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 수: 4070, feature shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "# feature의 shape 확인(fc layer 이전은 512개의 feature)\n",
    "print(f\"이미지 수: {len(extracted_features)}, feature shape: {extracted_features[t_img_list[0]].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T_00253_60_popart_W.jpg</th>\n",
       "      <td>1.057588</td>\n",
       "      <td>0.499090</td>\n",
       "      <td>0.964764</td>\n",
       "      <td>1.991788</td>\n",
       "      <td>0.861173</td>\n",
       "      <td>0.732690</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>1.579639</td>\n",
       "      <td>2.082400</td>\n",
       "      <td>1.172687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430914</td>\n",
       "      <td>2.368689</td>\n",
       "      <td>0.886840</td>\n",
       "      <td>0.572086</td>\n",
       "      <td>0.033725</td>\n",
       "      <td>0.119491</td>\n",
       "      <td>1.169548</td>\n",
       "      <td>0.377159</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.139832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_00456_10_sportivecasual_M.jpg</th>\n",
       "      <td>0.705563</td>\n",
       "      <td>0.464909</td>\n",
       "      <td>0.736676</td>\n",
       "      <td>0.601670</td>\n",
       "      <td>1.329381</td>\n",
       "      <td>1.628532</td>\n",
       "      <td>0.797708</td>\n",
       "      <td>0.149928</td>\n",
       "      <td>0.418592</td>\n",
       "      <td>0.828327</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245656</td>\n",
       "      <td>0.928324</td>\n",
       "      <td>1.179201</td>\n",
       "      <td>1.576541</td>\n",
       "      <td>0.382095</td>\n",
       "      <td>0.652732</td>\n",
       "      <td>0.740255</td>\n",
       "      <td>0.341360</td>\n",
       "      <td>0.011737</td>\n",
       "      <td>0.868388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_00588_10_sportivecasual_M.jpg</th>\n",
       "      <td>0.280607</td>\n",
       "      <td>1.900605</td>\n",
       "      <td>0.076298</td>\n",
       "      <td>0.313563</td>\n",
       "      <td>0.938350</td>\n",
       "      <td>3.079298</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>0.039337</td>\n",
       "      <td>0.623045</td>\n",
       "      <td>1.935424</td>\n",
       "      <td>...</td>\n",
       "      <td>2.356834</td>\n",
       "      <td>0.991338</td>\n",
       "      <td>1.462100</td>\n",
       "      <td>0.746372</td>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.448638</td>\n",
       "      <td>0.771779</td>\n",
       "      <td>1.735500</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>1.359725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_00770_60_minimal_W.jpg</th>\n",
       "      <td>0.416201</td>\n",
       "      <td>1.589971</td>\n",
       "      <td>0.462377</td>\n",
       "      <td>1.117409</td>\n",
       "      <td>0.230992</td>\n",
       "      <td>0.833754</td>\n",
       "      <td>0.477335</td>\n",
       "      <td>1.091138</td>\n",
       "      <td>0.284210</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853099</td>\n",
       "      <td>0.660150</td>\n",
       "      <td>0.992873</td>\n",
       "      <td>0.510357</td>\n",
       "      <td>0.281411</td>\n",
       "      <td>0.485778</td>\n",
       "      <td>0.390882</td>\n",
       "      <td>0.790282</td>\n",
       "      <td>1.029764</td>\n",
       "      <td>0.378048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_00893_90_hiphop_W.jpg</th>\n",
       "      <td>1.480315</td>\n",
       "      <td>1.115098</td>\n",
       "      <td>1.787921</td>\n",
       "      <td>0.440522</td>\n",
       "      <td>1.454214</td>\n",
       "      <td>0.438948</td>\n",
       "      <td>0.314583</td>\n",
       "      <td>0.311655</td>\n",
       "      <td>1.567511</td>\n",
       "      <td>1.217266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.076454</td>\n",
       "      <td>1.226675</td>\n",
       "      <td>1.402020</td>\n",
       "      <td>1.062232</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>0.092353</td>\n",
       "      <td>1.047830</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>0.116192</td>\n",
       "      <td>0.618304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_71923_60_mods_M.jpg</th>\n",
       "      <td>0.185352</td>\n",
       "      <td>0.538911</td>\n",
       "      <td>0.294497</td>\n",
       "      <td>0.886722</td>\n",
       "      <td>0.758606</td>\n",
       "      <td>0.501546</td>\n",
       "      <td>0.323596</td>\n",
       "      <td>1.483522</td>\n",
       "      <td>0.892440</td>\n",
       "      <td>1.113719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.255762</td>\n",
       "      <td>0.779979</td>\n",
       "      <td>1.605300</td>\n",
       "      <td>1.090727</td>\n",
       "      <td>0.511891</td>\n",
       "      <td>0.438244</td>\n",
       "      <td>0.434495</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>1.116629</td>\n",
       "      <td>0.613483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_71933_60_mods_M.jpg</th>\n",
       "      <td>0.308852</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>0.272143</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.539355</td>\n",
       "      <td>1.296929</td>\n",
       "      <td>0.430950</td>\n",
       "      <td>1.022277</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>0.679997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785857</td>\n",
       "      <td>0.480779</td>\n",
       "      <td>1.326938</td>\n",
       "      <td>0.378008</td>\n",
       "      <td>0.822803</td>\n",
       "      <td>0.701973</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.191141</td>\n",
       "      <td>0.979934</td>\n",
       "      <td>1.377376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_71934_60_mods_M.jpg</th>\n",
       "      <td>0.161009</td>\n",
       "      <td>0.474238</td>\n",
       "      <td>0.739945</td>\n",
       "      <td>0.385359</td>\n",
       "      <td>0.705802</td>\n",
       "      <td>0.236488</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>2.100184</td>\n",
       "      <td>0.587470</td>\n",
       "      <td>0.627063</td>\n",
       "      <td>...</td>\n",
       "      <td>1.466490</td>\n",
       "      <td>0.781835</td>\n",
       "      <td>2.687330</td>\n",
       "      <td>0.803959</td>\n",
       "      <td>0.546261</td>\n",
       "      <td>0.539433</td>\n",
       "      <td>0.416490</td>\n",
       "      <td>0.315864</td>\n",
       "      <td>1.944892</td>\n",
       "      <td>0.463204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_71935_60_mods_M.jpg</th>\n",
       "      <td>0.368237</td>\n",
       "      <td>0.493736</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.622802</td>\n",
       "      <td>0.770126</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.617757</td>\n",
       "      <td>1.709467</td>\n",
       "      <td>0.818570</td>\n",
       "      <td>0.821341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801818</td>\n",
       "      <td>0.785893</td>\n",
       "      <td>2.120833</td>\n",
       "      <td>0.632633</td>\n",
       "      <td>0.727804</td>\n",
       "      <td>0.279642</td>\n",
       "      <td>0.538590</td>\n",
       "      <td>0.084149</td>\n",
       "      <td>1.645151</td>\n",
       "      <td>0.717943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_71936_60_mods_M.jpg</th>\n",
       "      <td>0.397896</td>\n",
       "      <td>0.530444</td>\n",
       "      <td>0.770282</td>\n",
       "      <td>0.057157</td>\n",
       "      <td>1.468163</td>\n",
       "      <td>0.303290</td>\n",
       "      <td>0.467536</td>\n",
       "      <td>1.226217</td>\n",
       "      <td>1.072464</td>\n",
       "      <td>0.549205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216100</td>\n",
       "      <td>0.736215</td>\n",
       "      <td>3.253037</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.027546</td>\n",
       "      <td>0.715938</td>\n",
       "      <td>0.559784</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>1.976545</td>\n",
       "      <td>0.429012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0         1         2         3    \\\n",
       "T_00253_60_popart_W.jpg          1.057588  0.499090  0.964764  1.991788   \n",
       "T_00456_10_sportivecasual_M.jpg  0.705563  0.464909  0.736676  0.601670   \n",
       "T_00588_10_sportivecasual_M.jpg  0.280607  1.900605  0.076298  0.313563   \n",
       "T_00770_60_minimal_W.jpg         0.416201  1.589971  0.462377  1.117409   \n",
       "T_00893_90_hiphop_W.jpg          1.480315  1.115098  1.787921  0.440522   \n",
       "...                                   ...       ...       ...       ...   \n",
       "W_71923_60_mods_M.jpg            0.185352  0.538911  0.294497  0.886722   \n",
       "W_71933_60_mods_M.jpg            0.308852  0.314811  0.272143  0.815783   \n",
       "W_71934_60_mods_M.jpg            0.161009  0.474238  0.739945  0.385359   \n",
       "W_71935_60_mods_M.jpg            0.368237  0.493736  0.818316  0.622802   \n",
       "W_71936_60_mods_M.jpg            0.397896  0.530444  0.770282  0.057157   \n",
       "\n",
       "                                      4         5         6         7    \\\n",
       "T_00253_60_popart_W.jpg          0.861173  0.732690  0.020497  1.579639   \n",
       "T_00456_10_sportivecasual_M.jpg  1.329381  1.628532  0.797708  0.149928   \n",
       "T_00588_10_sportivecasual_M.jpg  0.938350  3.079298  0.057795  0.039337   \n",
       "T_00770_60_minimal_W.jpg         0.230992  0.833754  0.477335  1.091138   \n",
       "T_00893_90_hiphop_W.jpg          1.454214  0.438948  0.314583  0.311655   \n",
       "...                                   ...       ...       ...       ...   \n",
       "W_71923_60_mods_M.jpg            0.758606  0.501546  0.323596  1.483522   \n",
       "W_71933_60_mods_M.jpg            0.539355  1.296929  0.430950  1.022277   \n",
       "W_71934_60_mods_M.jpg            0.705802  0.236488  0.879010  2.100184   \n",
       "W_71935_60_mods_M.jpg            0.770126  0.752600  0.617757  1.709467   \n",
       "W_71936_60_mods_M.jpg            1.468163  0.303290  0.467536  1.226217   \n",
       "\n",
       "                                      8         9    ...       502       503  \\\n",
       "T_00253_60_popart_W.jpg          2.082400  1.172687  ...  0.430914  2.368689   \n",
       "T_00456_10_sportivecasual_M.jpg  0.418592  0.828327  ...  1.245656  0.928324   \n",
       "T_00588_10_sportivecasual_M.jpg  0.623045  1.935424  ...  2.356834  0.991338   \n",
       "T_00770_60_minimal_W.jpg         0.284210  1.001748  ...  0.853099  0.660150   \n",
       "T_00893_90_hiphop_W.jpg          1.567511  1.217266  ...  2.076454  1.226675   \n",
       "...                                   ...       ...  ...       ...       ...   \n",
       "W_71923_60_mods_M.jpg            0.892440  1.113719  ...  1.255762  0.779979   \n",
       "W_71933_60_mods_M.jpg            0.521891  0.679997  ...  0.785857  0.480779   \n",
       "W_71934_60_mods_M.jpg            0.587470  0.627063  ...  1.466490  0.781835   \n",
       "W_71935_60_mods_M.jpg            0.818570  0.821341  ...  0.801818  0.785893   \n",
       "W_71936_60_mods_M.jpg            1.072464  0.549205  ...  1.216100  0.736215   \n",
       "\n",
       "                                      504       505       506       507  \\\n",
       "T_00253_60_popart_W.jpg          0.886840  0.572086  0.033725  0.119491   \n",
       "T_00456_10_sportivecasual_M.jpg  1.179201  1.576541  0.382095  0.652732   \n",
       "T_00588_10_sportivecasual_M.jpg  1.462100  0.746372  0.232039  0.448638   \n",
       "T_00770_60_minimal_W.jpg         0.992873  0.510357  0.281411  0.485778   \n",
       "T_00893_90_hiphop_W.jpg          1.402020  1.062232  0.992168  0.092353   \n",
       "...                                   ...       ...       ...       ...   \n",
       "W_71923_60_mods_M.jpg            1.605300  1.090727  0.511891  0.438244   \n",
       "W_71933_60_mods_M.jpg            1.326938  0.378008  0.822803  0.701973   \n",
       "W_71934_60_mods_M.jpg            2.687330  0.803959  0.546261  0.539433   \n",
       "W_71935_60_mods_M.jpg            2.120833  0.632633  0.727804  0.279642   \n",
       "W_71936_60_mods_M.jpg            3.253037  0.502046  1.027546  0.715938   \n",
       "\n",
       "                                      508       509       510       511  \n",
       "T_00253_60_popart_W.jpg          1.169548  0.377159  0.020128  0.139832  \n",
       "T_00456_10_sportivecasual_M.jpg  0.740255  0.341360  0.011737  0.868388  \n",
       "T_00588_10_sportivecasual_M.jpg  0.771779  1.735500  0.952510  1.359725  \n",
       "T_00770_60_minimal_W.jpg         0.390882  0.790282  1.029764  0.378048  \n",
       "T_00893_90_hiphop_W.jpg          1.047830  0.154575  0.116192  0.618304  \n",
       "...                                   ...       ...       ...       ...  \n",
       "W_71923_60_mods_M.jpg            0.434495  0.188024  1.116629  0.613483  \n",
       "W_71933_60_mods_M.jpg            0.348771  0.191141  0.979934  1.377376  \n",
       "W_71934_60_mods_M.jpg            0.416490  0.315864  1.944892  0.463204  \n",
       "W_71935_60_mods_M.jpg            0.538590  0.084149  1.645151  0.717943  \n",
       "W_71936_60_mods_M.jpg            0.559784  0.081395  1.976545  0.429012  \n",
       "\n",
       "[4070 rows x 512 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출된 특징을 데이터프레임으로 변환 후 저장\n",
    "t_feature_vectors = pd.DataFrame(extracted_features).T\n",
    "#t_feature_vectors.to_csv('train_feature_vectors.csv')\n",
    "t_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 유사도를 활용한 스타일 선호 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top100 선호도 데이터 로드\n",
    "t_top100_pref = pd.read_csv('top100_train_preference.csv')\n",
    "v_top100_pref = pd.read_csv('top100_val_preference.csv')\n",
    "\n",
    "t_top100_pref['스타일 선호 여부'] = t_top100_pref['스타일 선호 여부'].apply(lambda x: 1 if x == '스타일 선호' else 0)\n",
    "v_top100_pref['스타일 선호 여부'] = v_top100_pref['스타일 선호 여부'].apply(lambda x: 1 if x == '스타일 선호' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>파일명</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "      <td>[1.0575885, 0.49908996, 0.96476394, 1.9917883,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T_00456_10_sportivecasual_M.jpg</td>\n",
       "      <td>[0.7055633, 0.4649085, 0.7366763, 0.60167015, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T_00588_10_sportivecasual_M.jpg</td>\n",
       "      <td>[0.28060737, 1.9006052, 0.07629789, 0.31356296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T_00770_60_minimal_W.jpg</td>\n",
       "      <td>[0.41620094, 1.589971, 0.46237656, 1.1174088, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T_00893_90_hiphop_W.jpg</td>\n",
       "      <td>[1.4803153, 1.1150981, 1.7879208, 0.4405219, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>W_71923_60_mods_M.jpg</td>\n",
       "      <td>[0.1853519, 0.5389108, 0.2944971, 0.8867223, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>W_71933_60_mods_M.jpg</td>\n",
       "      <td>[0.3088518, 0.31481087, 0.2721426, 0.8157828, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>W_71934_60_mods_M.jpg</td>\n",
       "      <td>[0.16100864, 0.47423834, 0.7399452, 0.38535923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>W_71935_60_mods_M.jpg</td>\n",
       "      <td>[0.3682367, 0.49373567, 0.8183162, 0.6228021, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>W_71936_60_mods_M.jpg</td>\n",
       "      <td>[0.39789608, 0.5304439, 0.77028245, 0.05715669...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  파일명  \\\n",
       "0             T_00253_60_popart_W.jpg   \n",
       "1     T_00456_10_sportivecasual_M.jpg   \n",
       "2     T_00588_10_sportivecasual_M.jpg   \n",
       "3            T_00770_60_minimal_W.jpg   \n",
       "4             T_00893_90_hiphop_W.jpg   \n",
       "...                               ...   \n",
       "4065            W_71923_60_mods_M.jpg   \n",
       "4066            W_71933_60_mods_M.jpg   \n",
       "4067            W_71934_60_mods_M.jpg   \n",
       "4068            W_71935_60_mods_M.jpg   \n",
       "4069            W_71936_60_mods_M.jpg   \n",
       "\n",
       "                                         feature_vector  \n",
       "0     [1.0575885, 0.49908996, 0.96476394, 1.9917883,...  \n",
       "1     [0.7055633, 0.4649085, 0.7366763, 0.60167015, ...  \n",
       "2     [0.28060737, 1.9006052, 0.07629789, 0.31356296...  \n",
       "3     [0.41620094, 1.589971, 0.46237656, 1.1174088, ...  \n",
       "4     [1.4803153, 1.1150981, 1.7879208, 0.4405219, 1...  \n",
       "...                                                 ...  \n",
       "4065  [0.1853519, 0.5389108, 0.2944971, 0.8867223, 0...  \n",
       "4066  [0.3088518, 0.31481087, 0.2721426, 0.8157828, ...  \n",
       "4067  [0.16100864, 0.47423834, 0.7399452, 0.38535923...  \n",
       "4068  [0.3682367, 0.49373567, 0.8183162, 0.6228021, ...  \n",
       "4069  [0.39789608, 0.5304439, 0.77028245, 0.05715669...  \n",
       "\n",
       "[4070 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature vector 파일 각종 전처리\n",
    "t_feature = pd.read_csv('train_feature_vectors.csv', index_col=0)\n",
    "t_feature['feature_vector'] = t_feature.values.tolist()     # 512차원의 feature vector를 하나의 list로 변환\n",
    "t_feature_reset = t_feature.reset_index().rename(columns={'index': '파일명'})\n",
    "t_feature_simplified = t_feature_reset[['파일명', 'feature_vector']]    # 파일명과 feature vector만 남기기\n",
    "t_feature_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>파일명</th>\n",
       "      <th>스타일 선호 여부</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06753_60_mods_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.70436937, 0.5913673, 1.950396, 0.84063923, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06686_70_hippie_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.022540793, 0.39496934, 0.7694336, 0.0089152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368</td>\n",
       "      <td>W_15453_70_hippie_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.10546503, 0.09943376, 0.7443662, 0.8763011,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06843_60_mods_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.36511362, 0.88988304, 0.31558028, 0.4499632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06896_10_sportivecasual_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.49174654, 1.4860588, 1.1976274, 0.31256232,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_07095_00_metrosexual_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7742443, 1.3371912, 0.8389899, 0.722591, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>67975</td>\n",
       "      <td>T_21986_70_hippie_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.69457424, 0.4065542, 1.262427, 0.61637765, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>67975</td>\n",
       "      <td>T_21987_70_hippie_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.22798271, 0.7277869, 1.1448684, 0.23363097,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>67975</td>\n",
       "      <td>T_17800_19_normcore_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9351864, 1.3963087, 2.6302078, 1.1111004, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>67975</td>\n",
       "      <td>T_21991_70_hippie_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6115558, 0.48620528, 1.2084986, 0.36354256,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4454 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      응답자 ID                              파일명  스타일 선호 여부  \\\n",
       "0        368            W_06753_60_mods_M.jpg          1   \n",
       "1        368          W_06686_70_hippie_M.jpg          1   \n",
       "2        368          W_15453_70_hippie_M.jpg          0   \n",
       "3        368            W_06843_60_mods_M.jpg          1   \n",
       "4        368  W_06896_10_sportivecasual_M.jpg          1   \n",
       "...      ...                              ...        ...   \n",
       "4449   67975     W_07095_00_metrosexual_M.jpg          1   \n",
       "4450   67975          T_21986_70_hippie_M.jpg          0   \n",
       "4451   67975          T_21987_70_hippie_M.jpg          1   \n",
       "4452   67975        T_17800_19_normcore_M.jpg          1   \n",
       "4453   67975          T_21991_70_hippie_M.jpg          0   \n",
       "\n",
       "                                         feature_vector  \n",
       "0     [0.70436937, 0.5913673, 1.950396, 0.84063923, ...  \n",
       "1     [0.022540793, 0.39496934, 0.7694336, 0.0089152...  \n",
       "2     [0.10546503, 0.09943376, 0.7443662, 0.8763011,...  \n",
       "3     [0.36511362, 0.88988304, 0.31558028, 0.4499632...  \n",
       "4     [0.49174654, 1.4860588, 1.1976274, 0.31256232,...  \n",
       "...                                                 ...  \n",
       "4449  [0.7742443, 1.3371912, 0.8389899, 0.722591, 1....  \n",
       "4450  [0.69457424, 0.4065542, 1.262427, 0.61637765, ...  \n",
       "4451  [0.22798271, 0.7277869, 1.1448684, 0.23363097,...  \n",
       "4452  [0.9351864, 1.3963087, 2.6302078, 1.1111004, 1...  \n",
       "4453  [0.6115558, 0.48620528, 1.2084986, 0.36354256,...  \n",
       "\n",
       "[4454 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top100 선호도 데이터에 feature vector를 병합(left merge)\n",
    "t_merged_df = pd.merge(t_top100_pref, t_feature_simplified, on='파일명', how='left')\n",
    "t_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 계산(코사인 유사도)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "for i in range(len(v_top100_pref)):\n",
    "    userID = v_top100_pref.loc[i, '응답자 ID']\n",
    "    img_name = v_top100_pref.loc[i, '파일명']\n",
    "\n",
    "    # v_top100_pref의 img에 대한 feature vector 추출\n",
    "    val_img_path = \"../dataset/validation_image/\"\n",
    "    feature_vector = _extract_features(val_img_path + img_name)\n",
    "\n",
    "    # train image 중 해당 유저가 이미 평가한 image들만 추출\n",
    "    user_evaluated_items = t_merged_df.loc[t_merged_df['응답자 ID']==userID, :]\n",
    "\n",
    "    # 해당 유저가 평가한 image들과 v_top100_pref의 img에서 추출한 feature vector와 유사도 계산(코사인 유사도)\n",
    "    similarity = cosine_similarity([feature_vector], user_evaluated_items['feature_vector'].tolist())\n",
    "\n",
    "    # 유사도 벡터를 DataFrame으로 변환하여 직관적으로 보기 쉽게 변환\n",
    "    t_item_similarity_df = pd.DataFrame(similarity, index=[img_name], columns=user_evaluated_items['파일명'])\n",
    "\n",
    "    # 유사도가 가장 높은 이미지 추출 (!상위 5개에서 voting을 하는 등 추천 방식은 변환 가능할 것)\n",
    "    top_similar_item = t_item_similarity_df.T.sort_values(by=img_name, ascending=False).head(1).index[0]\n",
    "\n",
    "    # top_similar_item의 선호 여부 확인 -> 해당 값을 추천 결과로 사용\n",
    "    top_similar_item_pref = user_evaluated_items[user_evaluated_items['파일명'] == top_similar_item]['스타일 선호 여부'].values[0]\n",
    "\n",
    "    # 예측값 저장\n",
    "    pred_list.append(top_similar_item_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>파일명</th>\n",
       "      <th>스타일 선호 여부</th>\n",
       "      <th>선호도 예측</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>W_04622_60_mods_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368</td>\n",
       "      <td>W_04678_50_ivy_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368</td>\n",
       "      <td>W_15791_70_hippie_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368</td>\n",
       "      <td>W_16034_80_bold_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>W_06551_60_mods_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_07074_00_metrosexual_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_52578_50_ivy_M.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_17742_80_bold_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_26965_90_hiphop_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>67975</td>\n",
       "      <td>W_06985_00_metrosexual_M.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      응답자 ID                           파일명  스타일 선호 여부  선호도 예측\n",
       "0        368         W_04622_60_mods_M.jpg          1       1\n",
       "1        368          W_04678_50_ivy_M.jpg          1       1\n",
       "2        368       W_15791_70_hippie_M.jpg          0       0\n",
       "3        368         W_16034_80_bold_M.jpg          0       0\n",
       "4        368         W_06551_60_mods_M.jpg          0       0\n",
       "...      ...                           ...        ...     ...\n",
       "1097   67975  W_07074_00_metrosexual_M.jpg          1       1\n",
       "1098   67975          W_52578_50_ivy_M.jpg          1       1\n",
       "1099   67975         W_17742_80_bold_M.jpg          0       0\n",
       "1100   67975       W_26965_90_hiphop_M.jpg          0       0\n",
       "1101   67975  W_06985_00_metrosexual_M.jpg          0       0\n",
       "\n",
       "[1102 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v_top100_pref에 대한 예측값을 열에 추가\n",
    "v_top100_pref['선호도 예측'] = pred_list\n",
    "v_top100_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8367, Precision: 0.7991, Recall: 0.7919\n"
     ]
    }
   ],
   "source": [
    "# 성능지표 평가 (Accuracy / Precision / Recall)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(v_top100_pref['스타일 선호 여부'], v_top100_pref['선호도 예측'])\n",
    "precision = precision_score(v_top100_pref['스타일 선호 여부'], v_top100_pref['선호도 예측'])\n",
    "recall = recall_score(v_top100_pref['스타일 선호 여부'], v_top100_pref['선호도 예측'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
